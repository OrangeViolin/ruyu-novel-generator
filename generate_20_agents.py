#!/usr/bin/env python3
"""
ç”Ÿæˆ20ä¸ªæ¸ é“æ™ºèƒ½ä½“é…ç½®ï¼ˆåŒ…æ‹¬æ­¦å¿—çº¢å…¬ä¼—å·ï¼‰
"""
from docx import Document
import json
import re

def parse_submission_channels(docx_path):
    """è§£ææŠ•ç¨¿æ¸ é“Wordæ–‡æ¡£"""
    doc = Document(docx_path)

    channels = []
    current_channel = {}

    for para in doc.paragraphs:
        text = para.text.strip()
        if not text:
            continue

        # æ£€æµ‹æ˜¯å¦æ˜¯æ¸ é“åç§°ï¼ˆæ•°å­—å¼€å¤´ï¼‰
        if re.match(r'^\d+[ã€.]', text):
            # ä¿å­˜ä¸Šä¸€ä¸ªæ¸ é“
            if current_channel:
                channels.append(current_channel)

            # å¼€å§‹æ–°æ¸ é“
            channel_name = re.sub(r'^\d+[ã€.]\s*', '', text)
            current_channel = {
                'name': channel_name,
                'requirements': [],
                'word_count': None,
                'payment': None,
                'email': None,
                'category': None
            }
        elif current_channel:
            # è§£æå†…å®¹
            if 'è¦æ±‚' in text or 'çº¦ç¨¿' in text:
                current_channel['requirements'].append(text)
            elif 'ç¨¿è´¹' in text or 'æ”¯ä»˜' in text:
                current_channel['payment'] = text
            elif 'å­—æ•°' in text:
                # æå–å­—æ•°è¦æ±‚
                match = re.search(r'(\d+)\s*[-~è‡³]\s*(\d+)\s*å­—', text)
                if match:
                    current_channel['word_count'] = {
                        'min': int(match.group(1)),
                        'max': int(match.group(2))
                    }
                else:
                    match = re.search(r'(\d+)\s*å­—', text)
                    if match:
                        words = int(match.group(1))
                        current_channel['word_count'] = {'min': words*0.8, 'max': words*1.2, 'optimal': words}
            elif 'ä¿¡ç®±' in text or 'é‚®ç®±' in text or '@' in text:
                # æå–é‚®ç®±
                email_match = re.search(r'[\w\.-]+@[\w\.-]+\.\w+', text)
                if email_match:
                    current_channel['email'] = email_match.group()

    # ä¿å­˜æœ€åä¸€ä¸ªæ¸ é“
    if current_channel:
        channels.append(current_channel)

    return channels

def classify_channel(channel):
    """ä¸ºæ¸ é“åˆ†ç±»å¹¶ç”Ÿæˆæ™ºèƒ½ä½“é…ç½®"""
    name = channel['name'].lower()
    requirements = ' '.join(channel['requirements'])

    # æ™ºèƒ½åˆ†ç±»
    if 'æƒ…æ„Ÿ' in name or 'å©šå§»' in name or 'ä¸¤æ€§' in name or 'æ‹çˆ±' in name:
        category = 'emotion'
        tone = 'æ¸©æš–ã€å…±æƒ…ã€ç»†è…»'
        topics = ['äº²å¯†å…³ç³»', 'æƒ…æ„Ÿé—®é¢˜', 'å©šå§»ç»è¥', 'è‡ªæˆ‘æˆé•¿']
    elif 'æ•…äº‹' in name or 'éè™šæ„' in name or 'çœŸå®' in name:
        category = 'story'
        tone = 'çœŸå®ã€æœ‰æ¸©åº¦ã€ç»†èŠ‚ä¸°å¯Œ'
        topics = ['çœŸå®ç»å†', 'äººç‰©æ•…äº‹', 'æˆé•¿å†ç¨‹', 'ç¤¾ä¼šè§‚å¯Ÿ']
    elif 'äº²å­' in name or 'è‚²å„¿' in name or 'å®¶åº­' in name or 'ç«¥ä¹¦' in name:
        category = 'parenting'
        tone = 'äº²åˆ‡ã€å®ç”¨ã€æœ‰ç»éªŒæ„Ÿ'
        topics = ['è‚²å„¿ç»éªŒ', 'äº²å­å…³ç³»', 'å®¶åº­æ•™è‚²', 'å¦ˆå¦ˆæˆé•¿']
    elif 'èŒåœº' in name or 'è¡Œä¸š' in name or 'ç®¡ç†' in name:
        category = 'career'
        tone = 'ä¸“ä¸šã€æœ‰æ´å¯ŸåŠ›'
        topics = ['èŒåœºç»éªŒ', 'è¡Œä¸šè§‚å¯Ÿ', 'èŒä¸šå‘å±•']
    elif 'å¿ƒç†' in name or 'æƒ…ç»ª' in name or 'æˆé•¿' in name:
        category = 'psychology'
        tone = 'æ¸©æš–ã€æ·±åˆ»ã€å¼•å¯¼æ€§'
        topics = ['æƒ…ç»ªç®¡ç†', 'è‡ªæˆ‘è®¤çŸ¥', 'å¿ƒç†å¥åº·', 'ä¸ªäººæˆé•¿']
    else:
        category = 'general'
        tone = 'äº²åˆ‡ã€æœ‰æ·±åº¦'
        topics = ['ç”Ÿæ´»æ„Ÿæ‚Ÿ', 'ä¸ªäººæˆé•¿']

    # ç”Ÿæˆæ™ºèƒ½ä½“é…ç½®
    agent_config = {
        'name': channel['name'],
        'description': f"ä¸“ä¸ºã€{channel['name']}ã€‘å®šåˆ¶çš„æŠ•ç¨¿æ™ºèƒ½ä½“",
        'channel_type': category,
        'target_audience': f"å…³æ³¨{category}çš„è¯»è€…",
        'channel_characteristics': {
            'topics': topics,
            'tone': tone,
            'special_requirements': requirements
        },
        'length_requirements': channel.get('word_count', {'min': 1500, 'max': 5000}),
        'contact': {
            'email': channel.get('email'),
            'payment': channel.get('payment')
        },
        # é¢„è®¾çš„å†™ä½œé£æ ¼
        'writing_style': {
            'tone': tone,
            'sentence_style': 'æµç•…è‡ªç„¶ï¼Œæœ‰æ¸©åº¦',
            'opening_pattern': 'æ•…äº‹/æ¡ˆä¾‹å¼•å…¥æˆ–è§‚ç‚¹æŠ›å‡º',
            'closing_pattern': 'æ€»ç»“å‡åæˆ–è¡ŒåŠ¨å»ºè®®'
        },
        'content_structure': {
            'sections': ['å¼•å…¥', 'æ­£æ–‡', 'å‡å'],
            'story_ratio': 0.4 if category == 'story' else 0.2
        }
    }

    return agent_config

def create_wuzhihong_agent():
    """åˆ›å»ºæ­¦å¿—çº¢å…¬ä¼—å·æ™ºèƒ½ä½“"""
    return {
        'name': 'æ­¦å¿—çº¢å…¬ä¼—å·',
        'description': 'ä¸“ä¸ºã€æ­¦å¿—çº¢å…¬ä¼—å·ã€‘å®šåˆ¶çš„æŠ•ç¨¿æ™ºèƒ½ä½“ - ä¸“æ³¨å¿ƒç†å­¦ä¸ä¸ªäººæˆé•¿',
        'channel_type': 'psychology',
        'target_audience': '25-45å²å…³æ³¨è‡ªæˆ‘æˆé•¿å’Œå¿ƒç†å¥åº·çš„éƒ½å¸‚äººç¾¤',
        'channel_characteristics': {
            'topics': ['äº²å¯†å…³ç³»', 'æƒ…ç»ªç®¡ç†', 'è‡ªæˆ‘è®¤çŸ¥', 'åŸç”Ÿå®¶åº­', 'å¿ƒç†å¥åº·', 'ä¸ªäººæˆé•¿', 'å¿ƒç†åˆ›ä¼¤ç–—æ„ˆ'],
            'tone': 'æ¸©æš–ã€æ·±åˆ»ã€ä¸“ä¸šè€Œä¸å¤±æ¸©åº¦ï¼Œæœ‰æ´å¯ŸåŠ›',
            'special_requirements': 'éœ€è¦æœ‰çœŸå®æ¡ˆä¾‹æ”¯æ’‘ï¼Œé¿å…ç©ºæ´è¯´æ•™ï¼Œè¦æœ‰æ·±åº¦åˆ†æï¼Œæ–‡é£æ¸©æš–ä½†æœ‰åŠ›é‡'
        },
        'length_requirements': {'min': 2000, 'max': 5000},
        'contact': {
            'email': None,
            'payment': 'ä¼˜è´¨ç¨¿ä»¶ç¨¿è´¹ä¼˜åš'
        },
        'writing_style': {
            'tone': 'æ¸©æš–ã€æ·±åˆ»ã€ä¸“ä¸š',
            'sentence_style': 'æµç•…ä¼˜ç¾ï¼Œå¯Œæœ‰å“²ç†ï¼Œå–„ç”¨æ¯”å–»',
            'opening_pattern': 'ä»çœŸå®æ¡ˆä¾‹æˆ–ç”Ÿæ´»ç°è±¡å¼•å…¥',
            'closing_pattern': 'ç»™å‡ºæœ‰å¯å‘çš„æ€è€ƒå’Œè¡ŒåŠ¨å»ºè®®'
        },
        'content_structure': {
            'sections': ['ç°è±¡å¼•å…¥', 'æ·±åº¦åˆ†æ', 'æ¡ˆä¾‹æ”¯æ’‘', 'æ€»ç»“å‡å'],
            'story_ratio': 0.5
        }
    }

# æ‰§è¡Œè§£æ
if __name__ == "__main__":
    docx_path = "/Users/mac/Downloads/ç½‘æ–‡ç ”ç©¶/çº¿ä¸Šçº¿ä¸‹500+æŠ•ç¨¿æ¸ é“.docx"

    print("ğŸ“– æ­£åœ¨è§£ææŠ•ç¨¿æ¸ é“æ–‡æ¡£...")
    channels = parse_submission_channels(docx_path)
    print(f"âœ… æˆåŠŸè§£æ {len(channels)} ä¸ªæ¸ é“\n")

    # ç”Ÿæˆæ™ºèƒ½ä½“é…ç½® - å¤„ç†å‰19ä¸ª
    agent_configs = []
    for channel in channels[:19]:
        config = classify_channel(channel)
        agent_configs.append(config)
        print(f"ğŸ“ æ™ºèƒ½ä½“é…ç½®ï¼š{config['name']}")
        print(f"   ç±»å‹ï¼š{config['channel_type']}")
        print(f"   è¯é¢˜ï¼š{', '.join(config['channel_characteristics']['topics'][:3])}")
        print()

    # æ·»åŠ æ­¦å¿—çº¢å…¬ä¼—å·ä½œä¸ºç¬¬20ä¸ª
    wuzhihong = create_wuzhihong_agent()
    agent_configs.append(wuzhihong)
    print(f"ğŸ“ æ™ºèƒ½ä½“é…ç½®ï¼š{wuzhihong['name']} â­")
    print(f"   ç±»å‹ï¼š{wuzhihong['channel_type']}")
    print(f"   è¯é¢˜ï¼š{', '.join(wuzhihong['channel_characteristics']['topics'][:4])}")
    print()

    # ä¿å­˜ä¸ºJSON
    output_file = "submission_agents_config_20.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(agent_configs, f, ensure_ascii=False, indent=2)

    print(f"ğŸ‰ é…ç½®å·²ä¿å­˜åˆ° {output_file}")
    print(f"ğŸ“Š å…±ç”Ÿæˆ {len(agent_configs)} ä¸ªæ™ºèƒ½ä½“é…ç½®")
